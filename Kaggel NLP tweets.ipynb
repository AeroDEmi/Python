{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Compute the sigmoid of x\n",
    "\n",
    "    Arguments:\n",
    "    x -- A scalar or numpy array of any size.\n",
    "\n",
    "    Return:\n",
    "    s -- sigmoid(x)\n",
    "    \"\"\"\n",
    "    s = 1/(1+np.exp(-x))\n",
    "    return s\n",
    "\n",
    "def relu(x):\n",
    "    \"\"\"\n",
    "    Compute the relu of x\n",
    "\n",
    "    Arguments:\n",
    "    x -- A scalar or numpy array of any size.\n",
    "\n",
    "    Return:\n",
    "    s -- relu(x)\n",
    "    \"\"\"\n",
    "    s = np.maximum(0,x)\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(layer_dims):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    layer_dims -- python array (list) containing the dimensions of each layer in our network\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
    "                    W1 -- weight matrix of shape (layer_dims[l], layer_dims[l-1])\n",
    "                    b1 -- bias vector of shape (layer_dims[l], 1)\n",
    "                    Wl -- weight matrix of shape (layer_dims[l-1], layer_dims[l])\n",
    "                    bl -- bias vector of shape (1, layer_dims[l])\n",
    "                    \n",
    "    Tips:\n",
    "    - For example: the layer_dims for the \"Planar Data classification model\" would have been [2,2,1]. \n",
    "    This means W1's shape was (2,2), b1 was (1,2), W2 was (2,1) and b2 was (1,1). Now you have to generalize it!\n",
    "    - In the for loop, use parameters['W' + str(l)] to access Wl, where l is the iterative integer.\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(3)\n",
    "    parameters = {}\n",
    "    L = len(layer_dims) # number of layers in the network\n",
    "\n",
    "    for l in range(1, L):\n",
    "        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1])*  np.sqrt(2 / layer_dims[l-1])\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
    "        \n",
    "        #assert(parameters['W' + str(l)].shape == layer_dims[l], layer_dims[l-1])\n",
    "        #assert(parameters['W' + str(l)].shape == layer_dims[l], 1)\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(a3, Y):\n",
    "    \n",
    "    \"\"\"\n",
    "    Implement the cost function\n",
    "    \n",
    "    Arguments:\n",
    "    a3 -- post-activation, output of forward propagation\n",
    "    Y -- \"true\" labels vector, same shape as a3\n",
    "    \n",
    "    Returns:\n",
    "    cost - value of the cost function\n",
    "    \"\"\"\n",
    "    m = Y.shape[1]\n",
    "    \n",
    "    logprobs = np.multiply(-np.log(a3),Y) + np.multiply(-np.log(1 - a3), 1 - Y)\n",
    "    cost = 1./m * np.sum(logprobs)\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation (and computes the loss) presented in Figure 2.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\":\n",
    "                    W1 -- weight matrix of shape ()\n",
    "                    b1 -- bias vector of shape ()\n",
    "                    W2 -- weight matrix of shape ()\n",
    "                    b2 -- bias vector of shape ()\n",
    "                    W3 -- weight matrix of shape ()\n",
    "                    b3 -- bias vector of shape ()\n",
    "    \n",
    "    Returns:\n",
    "    loss -- the loss function (vanilla logistic loss)\n",
    "    \"\"\"\n",
    "    \n",
    "    # retrieve parameters\n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    W3 = parameters[\"W3\"]\n",
    "    b3 = parameters[\"b3\"]\n",
    "    W4 = parameters[\"W4\"]\n",
    "    b4 = parameters[\"b4\"]\n",
    "    \n",
    "    # LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SIGMOID\n",
    "    z1 = np.dot(W1, X) + b1\n",
    "    a1 = relu(z1)\n",
    "    z2 = np.dot(W2, a1) + b2\n",
    "    a2 = relu(z2)\n",
    "    z3 = np.dot(W3, a2) + b3\n",
    "    a3 = relu(z3)\n",
    "    z4 = np.dot(W4, a3) + b4\n",
    "    a4 = sigmoid(z4)\n",
    "    \n",
    "    cache = (z1, a1, W1, b1, z2, a2, W2, b2, z3, a3, W3, b3, z4, a4, W4, b4)\n",
    "    \n",
    "    return a4, cache\n",
    "\n",
    "def backward_propagation(X, Y, cache):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation presented in figure 2.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset, of shape (input size, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat)\n",
    "    cache -- cache output from forward_propagation()\n",
    "    \n",
    "    Returns:\n",
    "    gradients -- A dictionary with the gradients with respect to each parameter, activation and pre-activation variables\n",
    "    \"\"\"\n",
    "    m = X.shape[1]\n",
    "    (z1, a1, W1, b1, z2, a2, W2, b2, z3, a3, W3, b3, z4, a4, W4, b4) = cache\n",
    "    \n",
    "    dz4 = 1./m * (a4 - Y)\n",
    "    dW4 = np.dot(dz4, a3.T)\n",
    "    db4 = np.sum(dz4, axis=1, keepdims = True)\n",
    "    \n",
    "    da3 = np.dot(W4.T, dz4)\n",
    "    dz3 = np.multiply(da3, np.int64(a3 > 0))\n",
    "    dW3 = np.dot(dz3, a2.T)\n",
    "    db3 = np.sum(dz3, axis=1, keepdims = True)\n",
    "    \n",
    "    da2 = np.dot(W3.T, dz3)\n",
    "    dz2 = np.multiply(da2, np.int64(a2 > 0))\n",
    "    dW2 = np.dot(dz2, a1.T)\n",
    "    db2 = np.sum(dz2, axis=1, keepdims = True)\n",
    "    \n",
    "    da1 = np.dot(W2.T, dz2)\n",
    "    dz1 = np.multiply(da1, np.int64(a1 > 0))\n",
    "    dW1 = np.dot(dz1, X.T)\n",
    "    db1 = np.sum(dz1, axis=1, keepdims = True)\n",
    "    \n",
    "    gradients = {\"dz4\": dz4, \"dW4\": dW4, \"db4\": db4,\n",
    "                 \"da3\": da3, \"dz3\": dz3, \"dW3\": dW3, \"db3\": db3,\n",
    "                 \"da2\": da2, \"dz2\": dz2, \"dW2\": dW2, \"db2\": db2,\n",
    "                 \"da1\": da1, \"dz1\": dz1, \"dW1\": dW1, \"db1\": db1}\n",
    "    \n",
    "    return gradients\n",
    "def predict(X, y, parameters):\n",
    "    \"\"\"\n",
    "    This function is used to predict the results of a  n-layer neural network.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- data set of examples you would like to label\n",
    "    parameters -- parameters of the trained model\n",
    "    \n",
    "    Returns:\n",
    "    p -- predictions for the given dataset X\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    p = np.zeros((1,m), dtype = np.int)\n",
    "    \n",
    "    # Forward propagation\n",
    "    a4, caches = forward_propagation(X, parameters)\n",
    "    \n",
    "    # convert probas to 0/1 predictions\n",
    "    for i in range(0, a4.shape[1]):\n",
    "        if a4[0,i] > 0.5:\n",
    "            p[0,i] = 1\n",
    "        else:\n",
    "            p[0,i] = 0\n",
    "\n",
    "    # print results\n",
    "\n",
    "    #print (\"predictions: \" + str(p[0,:]))\n",
    "    #print (\"true labels: \" + str(y[0,:]))\n",
    "    #print(\"Accuracy: \"  + str(np.mean((p[0,:] == y[0,:]))))\n",
    "    \n",
    "    return p\n",
    "\n",
    "\n",
    "\n",
    "def random_mini_batches(X, Y, mini_batch_size = 64):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (input size, number of examples)\n",
    "    Y -- true \"label\" vector (1 for blue dot / 0 for red dot), of shape (1, number of examples)\n",
    "    mini_batch_size -- size of the mini-batches, integer\n",
    "    \n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed()            # To make your \"random\" minibatches the same as ours\n",
    "    m = X.shape[1]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    \n",
    "    if mini_batch_size == 1:\n",
    "        for k in range(0,m):\n",
    "            mini_batch_X = X\n",
    "            mini_batch_Y = Y\n",
    "            mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "            mini_batches.append(mini_batch)\n",
    "        return mini_batches\n",
    "        \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_Y = Y[:, permutation].reshape((1,m))\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        mini_batch_X = shuffled_X[:,(k)*mini_batch_size: (k+1)*mini_batch_size]\n",
    "        mini_batch_Y = shuffled_Y[:,(k)*mini_batch_size: (k+1)*mini_batch_size]\n",
    "        ### END CODE HERE ###\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        mini_batch_X = shuffled_X[:,num_complete_minibatches*mini_batch_size:]\n",
    "        mini_batch_Y = shuffled_Y[:,num_complete_minibatches*mini_batch_size:]\n",
    "        ### END CODE HERE ###\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches\n",
    "\n",
    "# GRADED FUNCTION: initialize_adam\n",
    "\n",
    "def initialize_adam(parameters) :\n",
    "    \"\"\"\n",
    "    Initializes v and s as two python dictionaries with:\n",
    "                - keys: \"dW1\", \"db1\", ..., \"dWL\", \"dbL\" \n",
    "                - values: numpy arrays of zeros of the same shape as the corresponding gradients/parameters.\n",
    "    \n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing your parameters.\n",
    "                    parameters[\"W\" + str(l)] = Wl\n",
    "                    parameters[\"b\" + str(l)] = bl\n",
    "    \n",
    "    Returns: \n",
    "    v -- python dictionary that will contain the exponentially weighted average of the gradient.\n",
    "                    v[\"dW\" + str(l)] = ...\n",
    "                    v[\"db\" + str(l)] = ...\n",
    "    s -- python dictionary that will contain the exponentially weighted average of the squared gradient.\n",
    "                    s[\"dW\" + str(l)] = ...\n",
    "                    s[\"db\" + str(l)] = ...\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    L = len(parameters) // 2 # number of layers in the neural networks\n",
    "    v = {}\n",
    "    s = {}\n",
    "    \n",
    "    # Initialize v, s. Input: \"parameters\". Outputs: \"v, s\".\n",
    "    for l in range(L):\n",
    "    ### START CODE HERE ### (approx. 4 lines)\n",
    "        v[\"dW\" + str(l+1)] = np.zeros((parameters[\"W\"+str(l+1)].shape[0],parameters[\"W\"+str(l+1)].shape[1]))\n",
    "        v[\"db\" + str(l+1)] = np.zeros((parameters[\"b\"+str(l+1)].shape[0],parameters[\"b\"+str(l+1)].shape[1]))\n",
    "        s[\"dW\" + str(l+1)] = np.zeros((parameters[\"W\"+str(l+1)].shape[0],parameters[\"W\"+str(l+1)].shape[1]))\n",
    "        s[\"db\" + str(l+1)] = np.zeros((parameters[\"b\"+str(l+1)].shape[0],parameters[\"b\"+str(l+1)].shape[1]))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return v, s\n",
    "def update_parameters_with_adam(parameters, grads, v, s, t, learning_rate = 0.01,\n",
    "                                beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8):\n",
    "    \"\"\"\n",
    "    Update parameters using Adam\n",
    "    \n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing your parameters:\n",
    "                    parameters['W' + str(l)] = Wl\n",
    "                    parameters['b' + str(l)] = bl\n",
    "    grads -- python dictionary containing your gradients for each parameters:\n",
    "                    grads['dW' + str(l)] = dWl\n",
    "                    grads['db' + str(l)] = dbl\n",
    "    v -- Adam variable, moving average of the first gradient, python dictionary\n",
    "    s -- Adam variable, moving average of the squared gradient, python dictionary\n",
    "    learning_rate -- the learning rate, scalar.\n",
    "    beta1 -- Exponential decay hyperparameter for the first moment estimates \n",
    "    beta2 -- Exponential decay hyperparameter for the second moment estimates \n",
    "    epsilon -- hyperparameter preventing division by zero in Adam updates\n",
    "\n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your updated parameters \n",
    "    v -- Adam variable, moving average of the first gradient, python dictionary\n",
    "    s -- Adam variable, moving average of the squared gradient, python dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    L = len(parameters) // 2                 # number of layers in the neural networks\n",
    "    v_corrected = {}                         # Initializing first moment estimate, python dictionary\n",
    "    s_corrected = {}                         # Initializing second moment estimate, python dictionary\n",
    "    \n",
    "    # Perform Adam update on all parameters\n",
    "    for l in range(L):\n",
    "        # Moving average of the gradients. Inputs: \"v, grads, beta1\". Output: \"v\".\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        v[\"dW\" + str(l+1)] = beta1*v[\"dW\" + str(l+1)] + (1-beta1)*grads['dW' + str(l+1)]\n",
    "        v[\"db\" + str(l+1)] = beta1*v[\"db\" + str(l+1)] + (1-beta1)*grads['db' + str(l+1)]\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        # Compute bias-corrected first moment estimate. Inputs: \"v, beta1, t\". Output: \"v_corrected\".\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        v_corrected[\"dW\" + str(l+1)] = v[\"dW\" + str(l+1)]/(1-beta1**t)\n",
    "        v_corrected[\"db\" + str(l+1)] = v[\"db\" + str(l+1)]/(1-beta1**t)\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        # Moving average of the squared gradients. Inputs: \"s, grads, beta2\". Output: \"s\".\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        s[\"dW\" + str(l+1)] = beta2*s[\"dW\" + str(l+1)] + (1-beta2)*grads['dW' + str(l+1)]**2\n",
    "        s[\"db\" + str(l+1)] = beta2*s[\"db\" + str(l+1)] + (1-beta2)*grads['db' + str(l+1)]**2\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        # Compute bias-corrected second raw moment estimate. Inputs: \"s, beta2, t\". Output: \"s_corrected\".\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        s_corrected[\"dW\" + str(l+1)] = s[\"dW\" + str(l+1)]/(1-beta2**t)\n",
    "        s_corrected[\"db\" + str(l+1)] = s[\"db\" + str(l+1)]/(1-beta2**t)\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        # Update parameters. Inputs: \"parameters, learning_rate, v_corrected, s_corrected, epsilon\". Output: \"parameters\".\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate*v_corrected[\"dW\" + str(l+1)]/(np.sqrt(s_corrected[\"dW\" + str(l+1)])+epsilon)\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate*v_corrected[\"db\" + str(l+1)]/(np.sqrt(s_corrected[\"db\" + str(l+1)])+epsilon)\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "    return parameters, v, s\n",
    "\n",
    "# GRADED FUNCTION: initialize_velocity\n",
    "\n",
    "def initialize_velocity(parameters):\n",
    "    \"\"\"\n",
    "    Initializes the velocity as a python dictionary with:\n",
    "                - keys: \"dW1\", \"db1\", ..., \"dWL\", \"dbL\" \n",
    "                - values: numpy arrays of zeros of the same shape as the corresponding gradients/parameters.\n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing your parameters.\n",
    "                    parameters['W' + str(l)] = Wl\n",
    "                    parameters['b' + str(l)] = bl\n",
    "    \n",
    "    Returns:\n",
    "    v -- python dictionary containing the current velocity.\n",
    "                    v['dW' + str(l)] = velocity of dWl\n",
    "                    v['db' + str(l)] = velocity of dbl\n",
    "    \"\"\"\n",
    "    \n",
    "    L = len(parameters) // 2 # number of layers in the neural networks\n",
    "    v = {}\n",
    "    \n",
    "    # Initialize velocity\n",
    "    for l in range(L):\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        v[\"dW\" + str(l+1)] = np.zeros((parameters[\"W\"+str(l+1)].shape[0],parameters[\"W\"+str(l+1)].shape[1]))\n",
    "        v[\"db\" + str(l+1)] = np.zeros((parameters[\"b\"+str(l+1)].shape[0],parameters[\"b\"+str(l+1)].shape[1]))\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "    return v\n",
    "# GRADED FUNCTION: update_parameters_with_momentum\n",
    "\n",
    "def update_parameters_with_momentum(parameters, grads, v, beta, learning_rate):\n",
    "    \"\"\"\n",
    "    Update parameters using Momentum\n",
    "    \n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing your parameters:\n",
    "                    parameters['W' + str(l)] = Wl\n",
    "                    parameters['b' + str(l)] = bl\n",
    "    grads -- python dictionary containing your gradients for each parameters:\n",
    "                    grads['dW' + str(l)] = dWl\n",
    "                    grads['db' + str(l)] = dbl\n",
    "    v -- python dictionary containing the current velocity:\n",
    "                    v['dW' + str(l)] = ...\n",
    "                    v['db' + str(l)] = ...\n",
    "    beta -- the momentum hyperparameter, scalar\n",
    "    learning_rate -- the learning rate, scalar\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your updated parameters \n",
    "    v -- python dictionary containing your updated velocities\n",
    "    \"\"\"\n",
    "\n",
    "    L = len(parameters) // 2 # number of layers in the neural networks\n",
    "    \n",
    "    # Momentum update for each parameter\n",
    "    for l in range(L):\n",
    "        \n",
    "        ### START CODE HERE ### (approx. 4 lines)\n",
    "        # compute velocities\n",
    "        v[\"dW\" + str(l+1)] = beta*v[\"dW\" + str(l+1)] + (1-beta)*grads['dW' + str(l+1)]\n",
    "        v[\"db\" + str(l+1)] = beta*v[\"db\" + str(l+1)] + (1-beta)*grads['db' + str(l+1)]\n",
    "        # update parameters\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate*v[\"dW\" + str(l+1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate*v[\"db\" + str(l+1)]\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "    return parameters, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, Y, layers_dims, optimizer, learning_rate = 0.0007, mini_batch_size = 20, beta = 0.9,\n",
    "          beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8, num_epochs = 10000, print_cost = True):\n",
    "    \"\"\"\n",
    "    3-layer neural network model which can be run in different optimizer modes.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (2, number of examples)\n",
    "    Y -- true \"label\" vector (1 for blue dot / 0 for red dot), of shape (1, number of examples)\n",
    "    layers_dims -- python list, containing the size of each layer\n",
    "    learning_rate -- the learning rate, scalar.\n",
    "    mini_batch_size -- the size of a mini batch\n",
    "    beta -- Momentum hyperparameter\n",
    "    beta1 -- Exponential decay hyperparameter for the past gradients estimates \n",
    "    beta2 -- Exponential decay hyperparameter for the past squared gradients estimates \n",
    "    epsilon -- hyperparameter preventing division by zero in Adam updates\n",
    "    num_epochs -- number of epochs\n",
    "    print_cost -- True to print the cost every 1000 epochs\n",
    "\n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your updated parameters \n",
    "    \"\"\"\n",
    "    \n",
    "    L = len(layers_dims)             # number of layers in the neural networks\n",
    "    costs = []                       # to keep track of the cost\n",
    "    t = 0                            # initializing the counter required for Adam update\n",
    "    m = X.shape[1]                   # number of training examples\n",
    "    alpha=learning_rate\n",
    "    \n",
    "    # Initialize parameters\n",
    "    parameters = initialize_parameters(layers_dims)\n",
    "\n",
    "    # Initialize the optimizer\n",
    "    if optimizer == \"gd\":\n",
    "        pass # no initialization required for gradient descent\n",
    "    elif optimizer == \"momentum\":\n",
    "        v = initialize_velocity(parameters)\n",
    "    elif optimizer == \"adam\":\n",
    "        v, s = initialize_adam(parameters)\n",
    "    \n",
    "    # Optimization loop\n",
    "    for i in range(num_epochs):\n",
    "        \n",
    "        # Define the random minibatches. We increment the seed to reshuffle differently the dataset after each epoch\n",
    "        minibatches = random_mini_batches(X, Y, mini_batch_size)\n",
    "        cost_total = 0\n",
    "        \n",
    "        for minibatch in minibatches:\n",
    "            \n",
    "            # Select a minibatch\n",
    "            (minibatch_X, minibatch_Y) = minibatch\n",
    "\n",
    "            # Forward propagation\n",
    "            a3, caches = forward_propagation(minibatch_X, parameters)\n",
    "\n",
    "            # Compute cost and add to the cost total\n",
    "            cost_total += compute_cost(a3, minibatch_Y)\n",
    "\n",
    "            # Backward propagation\n",
    "            grads = backward_propagation(minibatch_X, minibatch_Y, caches)\n",
    "\n",
    "            # Update parameters\n",
    "            if optimizer == \"gd\":\n",
    "                parameters = update_parameters_with_gd(parameters, grads, learning_rate)\n",
    "            elif optimizer == \"momentum\":\n",
    "                parameters, v = update_parameters_with_momentum(parameters, grads, v, beta, learning_rate)\n",
    "            elif optimizer == \"adam\":\n",
    "                t = t + 1 # Adam counter\n",
    "                parameters, v, s = update_parameters_with_adam(parameters, grads, v, s,\n",
    "                                                               t, learning_rate, beta1, beta2,  epsilon)\n",
    "        cost_avg = cost_total / m\n",
    "        \n",
    "        # Print the cost every 1000 epoch\n",
    "        if print_cost and i % 1000 == 0:\n",
    "            print (\"Cost after epoch %i: %f, alpha %i: %f\" %(i, cost_avg, i, learning_rate))\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost_avg)\n",
    "        learning_rate = alpha * 0.999 ** i\n",
    "                \n",
    "    # plot the cost\n",
    "    plt.plot(costs)\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('epochs (per 100)')\n",
    "    plt.title(\"Learning rate = \" + str(learning_rate))\n",
    "    plt.show()\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/Users/emiliano/Downloads/nlp-getting-started/train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textstat as txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = (\n",
    "    \"Playing games has always been thought to be important to \"\n",
    "    \"the development of well-balanced and creative children; \"\n",
    "    \"however, what part, if any, they should play in the lives \"\n",
    "    \"of adults has never been researched that deeply. I believe \"\n",
    "    \"that playing games is every bit as important for adults \"\n",
    "    \"as for children. Not only is taking time out to play games \"\n",
    "    \"with our children and other adults valuable to building \"\n",
    "    \"interpersonal relationships but is also a wonderful way \"\n",
    "    \"to release built up tension.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school ',\n",
       " '@flowri were you marinading it or was it an accident?')"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.text[4],data.text[98]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = (data.text[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8.38, 7.8, 7.83, 16, 7.0, 0.0)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt.dale_chall_readability_score_v2(test_data),txt.automated_readability_index(test_data),txt.coleman_liau_index(test_data),txt.lexicon_count(test_data),txt.linsear_write_formula(test_data),txt.smog_index(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.71, 4.3, 5.6, 10, 6.0, 0.0)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = (data.text[98])\n",
    "txt.dale_chall_readability_score_v2(test_data),txt.automated_readability_index(test_data),txt.coleman_liau_index(test_data),txt.lexicon_count(test_data),txt.linsear_write_formula(test_data),txt.smog_index(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos el coleman liau index, automated readability y linsear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2.2, 78.0)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ntxt = data.keyword.apply(txt.automated_readability_index)\n",
    "Ntxt.min(), Ntxt.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 80.2)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ntxt = Ntxt + abs(Ntxt.min())\n",
    "Ntxt.min(),Ntxt.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nkey1,Nkey2,Nkey3 = data.keyword.apply(txt.automated_readability_index),data.keyword.apply(txt.coleman_liau_index),data.keyword.apply(txt.linsear_write_formula)\n",
    "Nkey1,Nkey2,Nkey3 = Nkey1 + abs(Nkey1.min()), Nkey2 + abs(Nkey2.min()), Nkey3 + abs(Nkey3.min())\n",
    "Nloc1,Nloc2,Nloc3 = data.location.apply(txt.automated_readability_index),data.location.apply(txt.coleman_liau_index),data.location.apply(txt.linsear_write_formula)\n",
    "Nloc1,Nloc2,Nloc3 = Nloc1 + abs(Nloc1.min()), Nloc2 + abs(Nloc2.min()), Nloc3 + abs(Nloc3.min())\n",
    "Ntxt1,Ntxt2,Ntxt3 = data.text.apply(txt.automated_readability_index),data.text.apply(txt.coleman_liau_index),data.text.apply(txt.linsear_write_formula)\n",
    "Ntxt1,Ntxt2,Ntxt3 = Ntxt1 + abs(Ntxt1.min()), Ntxt2 + abs(Ntxt2.min()), Ntxt3 + abs(Ntxt3.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x, col_max):\n",
    "    if x == -1:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return x/col_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>Nkey1</th>\n",
       "      <th>Nkey2</th>\n",
       "      <th>Nkey3</th>\n",
       "      <th>Nloc1</th>\n",
       "      <th>Nloc2</th>\n",
       "      <th>Nloc3</th>\n",
       "      <th>Ntxt1</th>\n",
       "      <th>Ntxt2</th>\n",
       "      <th>Ntxt3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.3</td>\n",
       "      <td>23.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>20.04</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.3</td>\n",
       "      <td>23.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>18.96</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.3</td>\n",
       "      <td>23.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.9</td>\n",
       "      <td>23.46</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.3</td>\n",
       "      <td>23.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.1</td>\n",
       "      <td>33.47</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.3</td>\n",
       "      <td>23.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.7</td>\n",
       "      <td>21.04</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1                   Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4                              Forest fire near La Ronge Sask. Canada   \n",
       "2   5                   All residents asked to 'shelter in place' are ...   \n",
       "3   6                   13,000 people receive #wildfires evacuation or...   \n",
       "4   7                   Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  Nkey1  Nkey2  Nkey3  Nloc1  Nloc2  Nloc3  Ntxt1  Ntxt2  Ntxt3  \n",
       "0       1    2.2    6.4    0.0   16.3   23.8    0.0   14.6  20.04    6.0  \n",
       "1       1    2.2    6.4    0.0   16.3   23.8    0.0   12.5  18.96    3.0  \n",
       "2       1    2.2    6.4    0.0   16.3   23.8    0.0   16.9  23.46    7.5  \n",
       "3       1    2.2    6.4    0.0   16.3   23.8    0.0   25.1  33.47    5.5  \n",
       "4       1    2.2    6.4    0.0   16.3   23.8    0.0   16.7  21.04    7.5  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Nkey1'],data['Nkey2'],data['Nkey3']=Nkey1,Nkey2,Nkey3\n",
    "data['Nloc1'],data['Nloc2'],data['Nloc3']=Nloc1,Nloc2,Nloc3\n",
    "data['Ntxt1'],data['Ntxt2'],data['Ntxt3']=Ntxt1,Ntxt2,Ntxt3\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>Nkey1</th>\n",
       "      <th>Nkey2</th>\n",
       "      <th>Nkey3</th>\n",
       "      <th>Nloc1</th>\n",
       "      <th>Nloc2</th>\n",
       "      <th>Nloc3</th>\n",
       "      <th>Ntxt1</th>\n",
       "      <th>Ntxt2</th>\n",
       "      <th>Ntxt3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.027431</td>\n",
       "      <td>0.068958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.080454</td>\n",
       "      <td>0.102582</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.179141</td>\n",
       "      <td>0.230107</td>\n",
       "      <td>0.315789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>0.027431</td>\n",
       "      <td>0.068958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.080454</td>\n",
       "      <td>0.102582</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.153374</td>\n",
       "      <td>0.217706</td>\n",
       "      <td>0.157895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.027431</td>\n",
       "      <td>0.068958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.080454</td>\n",
       "      <td>0.102582</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.207362</td>\n",
       "      <td>0.269377</td>\n",
       "      <td>0.394737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.027431</td>\n",
       "      <td>0.068958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.080454</td>\n",
       "      <td>0.102582</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.307975</td>\n",
       "      <td>0.384315</td>\n",
       "      <td>0.289474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.027431</td>\n",
       "      <td>0.068958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.080454</td>\n",
       "      <td>0.102582</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.204908</td>\n",
       "      <td>0.241589</td>\n",
       "      <td>0.394737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1                   Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4                              Forest fire near La Ronge Sask. Canada   \n",
       "2   5                   All residents asked to 'shelter in place' are ...   \n",
       "3   6                   13,000 people receive #wildfires evacuation or...   \n",
       "4   7                   Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target     Nkey1     Nkey2  Nkey3     Nloc1     Nloc2  Nloc3     Ntxt1  \\\n",
       "0       1  0.027431  0.068958    0.0  0.080454  0.102582    0.0  0.179141   \n",
       "1       1  0.027431  0.068958    0.0  0.080454  0.102582    0.0  0.153374   \n",
       "2       1  0.027431  0.068958    0.0  0.080454  0.102582    0.0  0.207362   \n",
       "3       1  0.027431  0.068958    0.0  0.080454  0.102582    0.0  0.307975   \n",
       "4       1  0.027431  0.068958    0.0  0.080454  0.102582    0.0  0.204908   \n",
       "\n",
       "      Ntxt2     Ntxt3  \n",
       "0  0.230107  0.315789  \n",
       "1  0.217706  0.157895  \n",
       "2  0.269377  0.394737  \n",
       "3  0.384315  0.289474  \n",
       "4  0.241589  0.394737  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Ntxt1'] = data['Ntxt1'].apply(lambda x: normalize(x,data['Ntxt1'].max()))\n",
    "data['Ntxt2'] = data['Ntxt2'].apply(lambda x: normalize(x,data['Ntxt2'].max()))\n",
    "data['Ntxt3'] = data['Ntxt3'].apply(lambda x: normalize(x,data['Ntxt3'].max()))\n",
    "data['Nkey1'] = data['Nkey1'].apply(lambda x: normalize(x,data['Nkey1'].max()))\n",
    "data['Nkey2'] = data['Nkey2'].apply(lambda x: normalize(x,data['Nkey2'].max()))\n",
    "data['Nkey3'] = data['Nkey3'].apply(lambda x: normalize(x,data['Nkey3'].max()))\n",
    "data['Nloc1'] = data['Nloc1'].apply(lambda x: normalize(x,data['Nloc1'].max()))\n",
    "data['Nloc2'] = data['Nloc2'].apply(lambda x: normalize(x,data['Nloc2'].max()))\n",
    "data['Nloc3'] = data['Nloc3'].apply(lambda x: normalize(x,data['Nloc3'].max()))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 7613)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = ['Nkey1','Nkey2','Nkey3', 'Nloc1','Nloc2','Nloc3','Ntxt1','Ntxt2','Ntxt3']\n",
    "datax_train = data.loc[:, feature_cols].values.T\n",
    "datax_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 7613)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datay_train = data['target'].values\n",
    "datay_train = datay_train.reshape(1,-1)\n",
    "datay_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00014353502301939458"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = -4*np.random.rand()\n",
    "alpha = 10**r\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.546147371228934"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r=-3* np.random.rand()\n",
    "betar = 1-10**r\n",
    "betar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.000378, alpha 0: 0.000700\n",
      "Cost after epoch 1000: 0.000316, alpha 1000: 0.000258\n",
      "Cost after epoch 2000: 0.000314, alpha 2000: 0.000095\n",
      "Cost after epoch 3000: 0.000314, alpha 3000: 0.000035\n",
      "Cost after epoch 4000: 0.000314, alpha 4000: 0.000013\n",
      "Cost after epoch 5000: 0.000314, alpha 5000: 0.000005\n",
      "Cost after epoch 6000: 0.000314, alpha 6000: 0.000002\n",
      "Cost after epoch 7000: 0.000313, alpha 7000: 0.000001\n",
      "Cost after epoch 8000: 0.000314, alpha 8000: 0.000000\n",
      "Cost after epoch 9000: 0.000313, alpha 9000: 0.000000\n",
      "Cost after epoch 10000: 0.000314, alpha 10000: 0.000000\n",
      "Cost after epoch 11000: 0.000314, alpha 11000: 0.000000\n",
      "Cost after epoch 12000: 0.000313, alpha 12000: 0.000000\n",
      "Cost after epoch 13000: 0.000314, alpha 13000: 0.000000\n",
      "Cost after epoch 14000: 0.000314, alpha 14000: 0.000000\n",
      "Cost after epoch 15000: 0.000313, alpha 15000: 0.000000\n",
      "Cost after epoch 16000: 0.000314, alpha 16000: 0.000000\n",
      "Cost after epoch 17000: 0.000314, alpha 17000: 0.000000\n",
      "Cost after epoch 18000: 0.000314, alpha 18000: 0.000000\n",
      "Cost after epoch 19000: 0.000314, alpha 19000: 0.000000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEWCAYAAACwtjr+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXxcVf3/8dd7sjTpknSF7gttobTQAg0FRYSvoBQBq7IVkU0Q4Uu/Kvr1J3xRRAS/4vpVviwiUCoCLVSWyiL6FdmhtIUutFCaLnShLemWrkmb5PP7454kk8lMljI3aeXzfDzmkZlzzz333DuT+5lz7plzZWY455xzcUq0dwWcc8796/Ng45xzLnYebJxzzsXOg41zzrnYebBxzjkXOw82zjnnYufBxu0VSc9Iuqi96+Gc2z94sNnPSFoh6eT2roeZnWpmU9q7HgCSnpd0WTtsd5Kk2ZIqJd3XivWek2SScsPrAyQ9JOkDSeWSXpF0TFJ+SbpO0kpJWyVNlVSUtLy7pGmSNoTHA7XLJQ2UtD3lYZK+G5b3kTQjbNskDU6p68KUdask/SVp+RGS5kjaGf4ekbTse5LelrRN0nJJ38twPE4I274pKW2ipMXheHwoaUrKPj8vqSKpXotbcbw6SLo3LFsn6Tsp9eko6fZwLMslvZiy/ChJL4btrpf0rczvdmaS8iVND//TJunElOUtOn77Cw82rpHak+C+YF+qSxofADcB97Z0BUnnA6n71BmYBYwFugNTgKckdQ7LLwQuAI4D+gKFwK1J698EdAMOAoYCBwI3AJjZSjPrXPsADgdqgD+HdWuAvwJnpquvmY1KWrcLsBJ4JOxLPvAE8Kew/SnAEyEdQKHu3YDxwCRJE1OORx7wW2BmyqZfAY4zs+KwX7lhP5NNStq3Q5LSmzteNwDDgUHAvwH/T9L4pOV3Eb0Ph4a/VyfVt2c4Xr8HegDDgL81OnAt9zLwVWBdmmXNHr/9ipn5Yz96ACuAkzMsOx2YC2wBXgVGJy27BlgKbAMWAV9KWnYx0T/3b4BNRP/UFxP9I/wS2AwsB05NWud54LKk9ZvKOwR4MWz7/4DbgD9l2IcTgdXA94n+Ae8n+md7EigL5T8J9A/5bwaqgQpgO/C/IX0E8PewP4uBc2J8T24C7mtBvmLgPeBYwIDcJvJuBcaG59OB7yUt+2TY347h9TPAvyctvwp4NkO5PwL+mSY9N9RpcBN1OiEc407h9eeANYCS8qwExmdY/3fArSlp1wA/B+4DbsqwXmfgj8DT6T5/afI3d7zWAJ9LWv4TYGp4fkg49kUZyv4pcH8Tx2ivPnfhM39iM3kaHb/96eEtm38Rko4i+ob9DaJvXL8HZkjqELIsBY4nOuH9GPiTpD5JRRwDLAMOIDqB16YtBnoSnRDukaQMVWgq74PAG6FeNxB962xKb6JvlIOAy4la4JPD64HALuB/AczsOuAl6r/lTpLUiegf/sGwP+cBt0salW5joctkS4bH/Gbq2ho/Be4g/bfY5PocAeQDpbVJ4UHS6w5E384hCt6nS+omqRtRK+WZDMVfSNQC2RsXAdPNbEd4PQqYb+FMGMwP6Q2Ez8LxwMKktEHA14Ab021M0qcklRN9STkT+J+ULP8durpeSemCyni8wvHpC8xLWj4vqc7HAO8DPw5lL5CU3Oo7Ftgk6dXQvfcXSQNDfVv1uWuNdMdvv9Pe0c4frXuQoWVDdBL7SUraYuCEDOXMBSaE5xcDK1OWXwyUJr3uSPTNt3d4/TwNWzZp8xIFhyrCt8qw/E803bLZDRQ0cQyOADYnva6rS3h9LvBSyjq/B34U03vSbMsGKAnHPBcYTIaWDVAELACuTUq7jKhFNJjoy8KMsP4nwvK+RC3GmvD4O5CfpuzjiVomndMsa7JlE97TrSR9+wZ+SGgRJKU9ANyQZv0fE53UOySlPQGcG57fR+aWTT+iLykHJ6UdQ9St14EoCG4DhjZ3vIAB4XlBUlmfBVaE5/8Vlt9AFPBrW3OHhuXvEfUcHA0UELU2XvmonzuaadmkO37728NbNv86BgHfTf5WTvSP1RdA0oWS5iYtO4yoFVJrVZoy676Bm9nO8LRzmnxN5e0LbEpKy7StZGVmVlH7Ilyw/b2k9yVtJeqS6yopJ8P6g4BjUo7F+UTBr81JSgC3A98ys6om8hUCfwFeN7P/Tlp0L/AQUVBdCPwzpK8Ofx8hOgl2IQpWS4kCeqqLgD+b2fa92I0vE3UNvZCUtj1sL1kR0Ym/jqRJRC2q08ysMqSdAXQxs2nNbdjM1hBdJ5malDbTzLaZWaVFA1VeAT4fFjd1vGr3PbneyXXeBewhCny7zeyFsP7nkpY/Zmazwmf0x8AnJRXTxOdOKQM1mtvnZOmO3/5oX7746lpnFXCzmd2cuiB0V/wBOAl4zcyqJc2lYVdDXNN/rwW6S+qYFHAGNLNOal2+S9SXfoyZrQvdTG9RX//U/KuAF8zssy2poKQ7iS7SpvO+mX3UbpAiopbNtNCzWBskV0s628xeCt2djxNdT/hG8spmVkN0reVHob6110rWhCxjiK7Z7Ejan5eTywiB7GzgS3u5DxcBf7TwNTtYSPQFR0npo4m69Wq3+zWi6zKfNrPVSeueBJRIqv2SUgxUSzrczCak2X4u0eCHTIzweWjqeJlZjaS1RMfs72HdMdR3TzXXbTqfhp+32uei+c9dpi9qGTVx/PY73rLZP+VJKkh65BIFkyskHaNIJ0mnSeoCdCL6pygDkHQJUcsmdmb2PjAbuCEM9fwEcEYri+lC9I1yi6TuhJNIkvVEI5ZqPQkcLOkCSXnhcbSkQzPU8QpLGrGV8sgYaCTlSiogCh45Se9FqnKiFt4R4VH7DXwsMDOMyJoe9vHCcLJM3k53SUPD+zoS+DVwY1K+WcBlkgpDULmchtckIAoyW6j/lp9cfgFRdxRAh/A6eXl/olFbqdd6nicanPFNRcOJJ4X058J65xNdp/qsmS1LWfeHwMFJx2QG0Wf4ktp1Q2tA4cvSzcA/wrKukk6pPd5hO58Gnm3h8foj8ANF17hGAF8n6saDqNW8Erg2lH0cUdfus2H5ZOBLioZ854X9eNnMttDKz12oa/Lxzg/7pBYcv/1Pe/fj+aN1D6JrNpbyuCksG0904tlC1KJ4hKirAqJ/1k3ABqJ/vhdIGU2Wsp10aQYMC8+fb2b95LxDiS7ibyM6YdwF3JNh/04EVqek9Q3b207UXfQNkq55EPXFv0c0Uu13Ie0Q4CmiALuR6AR4RJbfixvSvBc3hGUDQ30HpllvcEr9Twivd4Z1ah/Hh+UHE11/20l08fo7KeUNIep+2xje478Cw1PyPEvKNb2U96rBI2X5taRci0hadiQwhyhQvgkcmbRsOVGXVPI+3ZmhnPtIumYTPq+rgR3h711Aj7CsF9HnfBvRZ/11ohMyLTxeHYi62rYSfVFJXT4KeC1su8HIzbD8SqKW0uZw3AckLWvV5470/8+DW3v89oeHwk4512YkTQPeNbPUFopz7l+Ud6O52IWuhKGSEop+PDeB6PqEc+5jwgcIuLbQG3iU6Hc2q4Erzeyt9q2Sc64teTeac8652Hk3mnPOudjF2o0W+ud/SzQ09G4z+1nK8g5EwxDHEo3cONfMVoRl1wKXEoZWmtmzTZUp6R6i3zKIaGTSxWa2XdFUElOArmGda8zs6abq3bNnTxs8ePBH3n/nnPs4mTNnzgYz65VuWWzdaOHX3e8RTQWxmmio4nlmtigpz78TTRZ5haLZTL9kZueGsfEPAeOon4rj4LBa2jIlFZnZ1lDur4EPzexnku4C3jKzO0K5T5vZ4KbqXlJSYrNnz87SkXDOuY8HSXPMrCTdsji70cYRzZe1zMx2E001kfrL4AnU/1BsOnBS+EHTBKI5lyrNbDnRhITjmiozKdCIaErx2ihq1E9NUUw0Lbxzzrk2FGew6UfDObBWh7S0eSyaM6qcaMRSpnWbLFPSZKI5ukZQf/+KG4CvSloNPA38R7rKSrpc0Y2wZpeVlbV4J51zzjUvzmCTbir61D67THlamx49MbuEqNvtHaIZWCGa5vs+M+tPNE3I/YomRmxYiNldZlZiZiW9eqXtcnTOObeX4gw2q2k44WJ/Gndh1eUJc0oVE023kWndZss0s2pgGvV3HrwUeDgse41oWvDk2Y6dc87FLM5gM4voZkVDFN0mdiLRZHvJZhDNJgtwFvCcRSMWZgATwyR1Q4huEvVGpjLDhHvDoO6azRnAu6HclUQzzBImxCsgTEjpnHOubcQ29NnMqsIssM8SDTm+18wWSroRmG1mM4B7iLq1SolaNBPDugslPUw0CV4VcFVosZChzAQwRVIRUVfbPKLJ8iCanv4Pkq4m6nK72PyXrM4516Z8BoE0fOizc861XnsNff7YmbViE7/622L2VNc0n9k55z5GPNhk0Zvvb+bW50rZXeXBxjnnknmwyaKcRDQyu9q7Jp1zrgEPNlmUiO7mSk2NBxvnnEvmwSaL6lo2Hmycc64BDzZZFGINHmucc64hDzZZlAjRpsav2TjnXAMebLIoR96N5pxz6XiwyaKEX7Nxzrm0PNhkUW3LxrvRnHOuIQ82WeSj0ZxzLj0PNlnkAwSccy49DzZZVD9AoJ0r4pxz+xgPNlmUE46md6M551xDHmyySD5AwDnn0vJgk0U+Gs0559LzYJNFPhrNOefS82CTRT4azTnn0vNgk0U+Gs0559LzYJNFCR+N5pxzaXmwySIfIOCcc+l5sMkiHyDgnHPpxRpsJI2XtFhSqaRr0izvIGlaWD5T0uCkZdeG9MWSTmmuTEn3SJonab6k6ZI6h/TfSJobHu9J2hLX/tbN+uwtG+ecayC2YCMpB7gNOBUYCZwnaWRKtkuBzWY2DPgNcEtYdyQwERgFjAdul5TTTJlXm9kYMxsNrAQmAZjZ1WZ2hJkdAdwKPBrXPidCN5p5sHHOuQbibNmMA0rNbJmZ7QamAhNS8kwApoTn04GTFP0MfwIw1cwqzWw5UBrKy1immW0FCOsXAunO+OcBD2VxHxvw0WjOOZdenMGmH7Aq6fXqkJY2j5lVAeVAjybWbbJMSZOBdcAIolYMScsGAUOA59JVVtLlkmZLml1WVtayPUzho9Gccy69OION0qSlnoUz5WltevTE7BKgL/AOcG5KvonAdDOrTldZM7vLzErMrKRXr17psjQrx3/U6ZxzacUZbFYDA5Je9wc+yJRHUi5QDGxqYt1mywzBZBpwZsq2JhJjFxokd6N5sHHOuWRxBptZwHBJQyTlE53sZ6TkmQFcFJ6fBTxn0dX1GcDEMFptCDAceCNTmYoMg7prNmcA79ZuRNIhQDfgtZj2FfDpapxzLpPcuAo2sypJk4BngRzgXjNbKOlGYLaZzQDuAe6XVErUopkY1l0o6WFgEVAFXFXb/ZWhzAQwRVIRUVfbPODKpOqcRzTgINYo4C0b55xLL7ZgA2BmTwNPp6Rdn/S8Ajg7w7o3Aze3sMwa4Lgm6nFDa+q9t/xHnc45l57PIJBF3o3mnHPpebDJohBr8IaNc8415MEmi/yajXPOpefBJou8G80559LzYJNF3rJxzrn0PNhkUcJHoznnXFoebLLIp6txzrn0PNhkkc/67Jxz6XmwyaLaWZ+9ZeOccw15sMkiHyDgnHPpebDJoto7dXrLxjnnGvJgk0V1v7Pxlo1zzjXgwSbLchKi2ls2zjnXgAebLMuRfDSac86l8GCTZYmEX7NxzrlUHmyyLGrZeLBxzrlkHmyyLJHwYOOcc6k82GRZTkLejeaccyk82GSZd6M551xjHmyyTJLfqdM551J4sMmynIT/qNM551LFGmwkjZe0WFKppGvSLO8gaVpYPlPS4KRl14b0xZJOaa5MSfdImidpvqTpkjonLTtH0iJJCyU9GN8eh240v2bjnHMNxBZsJOUAtwGnAiOB8ySNTMl2KbDZzIYBvwFuCeuOBCYCo4DxwO2Scpop82ozG2Nmo4GVwKRQ1nDgWuA4MxsFfDuufYZoNJq3bJxzrqE4WzbjgFIzW2Zmu4GpwISUPBOAKeH5dOAkSQrpU82s0syWA6WhvIxlmtlWgLB+IVB7xv86cJuZbQ75PoxlbwOfrsY55xqLM9j0A1YlvV4d0tLmMbMqoBzo0cS6TZYpaTKwDhgB3BqSDwYOlvSKpNcljU9XWUmXS5otaXZZWVlr9rMBH43mnHONxRlslCYt9SycKU9r06MnZpcAfYF3gHNDci4wHDgROA+4W1LXRoWY3WVmJWZW0qtXrzSbaZmE/87GOecaiTPYrAYGJL3uD3yQKY+kXKAY2NTEus2WaWbVwDTgzKRtPGFme0KX3GKi4BMLb9k451xjcQabWcBwSUMk5RNd8J+RkmcGcFF4fhbwnJlZSJ8YRqsNIQoOb2QqU5FhUHfN5gzg3VDu48C/hWU9ibrVlsWyx9ROVxNX6c45t3/KjatgM6uSNAl4FsgB7jWzhZJuBGab2QzgHuB+SaVELZqJYd2Fkh4GFgFVwFWhxUKGMhPAFElFRF1t84ArQ1WeBT4naRFQDXzPzDbGtd8JgXk3mnPONSA/MTZWUlJis2fP3qt1v/C/L9O9Uz73XTIuy7Vyzrl9m6Q5ZlaSbpnPIJBlCb9m45xzjXiwyTKf9dk55xrzYJNlPhrNOeca82CTZYkE1PhoNOeca8CDTZb5dDXOOdeYB5ss8wECzjnXmAebLMtJyH9n45xzKTzYZFnC72fjnHONeLDJsqgbrb1r4Zxz+xYPNlnmt4V2zrnGPNhkmY9Gc865xjzYZFlCflto55xL5cEmy7xl45xzjXmwyTKfrsY55xrzYJNliYR3oznnXCoPNlmWEHiscc65hjzYZJlfs3HOucY82GSZj0ZzzrnGPNhkmbdsnHOuMQ82WeazPjvnXGMebLIsx0ejOedcIx5sssy70ZxzrrFYg42k8ZIWSyqVdE2a5R0kTQvLZ0oanLTs2pC+WNIpzZUp6R5J8yTNlzRdUueQfrGkMklzw+OyOPc5GiAQ5xacc27/E1uwkZQD3AacCowEzpM0MiXbpcBmMxsG/Aa4Jaw7EpgIjALGA7dLymmmzKvNbIyZjQZWApOStjPNzI4Ij7vj2N9aOQm8ZeOccynibNmMA0rNbJmZ7QamAhNS8kwApoTn04GTJCmkTzWzSjNbDpSG8jKWaWZbAcL6hUC7nPETEjUebJxzroE4g00/YFXS69UhLW0eM6sCyoEeTazbZJmSJgPrgBHArUn5zkzqXhuQrrKSLpc0W9LssrKyFu9kqoSEGX5raOecSxJnsFGatNQzcKY8rU2PnphdAvQF3gHODcl/AQaH7rX/o74l1bAQs7vMrMTMSnr16pUuS4vkJKIq+vBn55yrF2ewWQ0ktyL6Ax9kyiMpFygGNjWxbrNlmlk1MA04M7zeaGaVYfEfgLF7vUctUBdsvGXjnHN14gw2s4DhkoZIyie64D8jJc8M4KLw/CzgOYv6n2YAE8NotSHAcOCNTGUqMgzqrtmcAbwbXvdJ2t4XiFo9sUkoCjY+Is055+rlxlWwmVVJmgQ8C+QA95rZQkk3ArPNbAZwD3C/pFKiFs3EsO5CSQ8Di4Aq4KrQYiFDmQlgiqQioq62ecCVoSrflPSFUM4m4OK49hmi0WjgLRvnnEsWW7ABMLOngadT0q5Pel4BnJ1h3ZuBm1tYZg1wXIZyrgWubW3d91Zty8av2TjnXL0WdaNJahQQ0qW5+ms2PmWNc87Va+k1m3QtgzZrLexPfICAc8411mQ3mqRTgc8D/ST9LmlREdE1EJdCtQMEPNg451yd5q7ZfADMJhrFNScpfRtwdVyV2p/l+Gg055xrpMlgY2bzgHmSHjSzPQCSugEDzGxzW1Rwf+Oj0ZxzrrGWXrP5u6QiSd2JhhVPlvTrGOu136r/nY0HG+ecq9XSYFMcJrr8MjDZzMYCJ8dXrf2XT1fjnHONtTTY5IZf4p8DPBljffZ7PhrNOecaa2mwuZHoV/tLzWyWpIOAJfFVa//l3WjOOddYi2YQMLNHgEeSXi8jTHTpGvKWjXPONdbSGQT6S3pM0oeS1kv6s6T+cVduf+TT1TjnXGMt7UabTDQTc1+im5X9JaS5FKFhgzdsnHOuXkuDTS8zm2xmVeFxH7D3dxj7F+aj0ZxzrrGWBpsNkr4qKSc8vgpsjLNi+6uEX7NxzrlGWhpsvkY07HkdsJboRmeXxFWp/VmOj0ZzzrlGWno/m58AF9VOURNmEvglURBySbwbzTnnGmtpy2Z08lxoZrYJODKeKu3f6kajeTeac87VaWmwSYQJOIG6lk2sd/ncX9XfPK2dK+Kcc/uQlgaMXwGvSpoOGNH1m0a3bHY+67NzzqXT0hkE/ihpNvAZQMCXzWxRrDXbT/l0Nc4511iLu8JCcPEA04yE36nTOecaaek1m70iabykxZJKJV2TZnkHSdPC8pmSBictuzakL5Z0SnNlSrpH0jxJ8yVNl9Q5ZVtnSTJJJfHsbcRHoznnXGOxBRtJOcBtwKnASOA8SSNTsl0KbDazYcBvgFvCuiOBicAoYDxwe+0PSpso82ozG2Nmo4GVwKSkunQBvgnMjGVnk3jLxjnnGouzZTMOKDWzZWa2G5gKTEjJMwGYEp5PB06SpJA+1cwqzWw5UBrKy1hmuLkbYf1CooEMtX4C/ByoyP5uNlTfsol7S845t/+IM9j0A1YlvV4d0tLmMbMqoBzo0cS6TZYpaTLRLAcjgFtD2pHAADNr8qZvki6XNFvS7LKyshbuYmM+Gs055xqLM9goTVrqGThTntamR0/MLiGamfod4FxJCaLuue82V1kzu8vMSsyspFevvZ9j1EejOedcY3EGm9XAgKTX/YEPMuWRlAsUA5uaWLfZMs2sGphGdHO3LsBhwPOSVgDHAjPiHCTgAwScc66xOIPNLGC4pCGS8oku+M9IyTMDuCg8Pwt4zswspE8Mo9WGAMOBNzKVqcgwqLtmcwbwrpmVm1lPMxtsZoOB14EvmNnsuHbap6txzrnGYptyxsyqJE0CngVygHvNbKGkG4HZZjYDuAe4X1IpUYtmYlh3oaSHiX7XUwVcFVosZCgzAUyRVETU1TYPuDKufWtK/XQ1Hmycc65WrPObmdnTwNMpadcnPa8Azs6w7s2kmRInQ5k1wHEtqM+JLan3R1E/9DnuLTnn3P4j1h91fhwlfDSac8414sEmy/zmac4515gHmyzz0WjOOdeYB5ssSyR8uhrnnEvlwSbLarvRvGXjnHP1PNhkWV03mrdsnHOujgebLPPpapxzrjEPNlnmsz4751xjHmyyLMQaHyDgnHNJPNhkmSQkDzbOOZfMg00MciQfjeacc0k82MQgkZCPRnPOuSQebGKQI/loNOecS+LBJgY5CfloNOecS+LBJgYJHyDgnHMNeLCJQWF+Drt2V7d3NZxzbp/hwSYGRQV5bK3Y097VcM65fYYHmxgUFXqwcc65ZB5sYlBUkMvWXVXtXQ3nnNtneLCJgbdsnHOuIQ82MSgqyGPrLg82zjlXK9ZgI2m8pMWSSiVdk2Z5B0nTwvKZkgYnLbs2pC+WdEpzZUq6R9I8SfMlTZfUOaRfIWmBpLmSXpY0Ms59BiguzGNrRRXmw5+dcw6IMdhIygFuA04FRgLnpTnRXwpsNrNhwG+AW8K6I4GJwChgPHC7pJxmyrzazMaY2WhgJTAppD9oZoeb2RHAz4Ffx7PH9YoKc6muMXb68GfnnAPibdmMA0rNbJmZ7QamAhNS8kwApoTn04GTJCmkTzWzSjNbDpSG8jKWaWZbAcL6hYAlpwedatPjVFSQB+DXbZxzLogz2PQDViW9Xh3S0uYxsyqgHOjRxLpNlilpMrAOGAHcmpR+laSlRC2bb36UnWqJosIQbHxEmnPOAfEGG6VJS21VZMrT2vToidklQF/gHeDcpPTbzGwo8H3gB2krK10uabak2WVlZemytJi3bJxzrqE4g81qYEDS6/7AB5nySMoFioFNTazbbJlmVg1MA85MU6epwBfTVdbM7jKzEjMr6dWrV5M71pyiwlwAH5HmnHNBnMFmFjBc0hBJ+UQX/Gek5JkBXBSenwU8Z9EQrhnAxDBabQgwHHgjU5mKDIO6azZnAO+G18OTtncasCSGfW2gtmVT7sHGOecAyI2rYDOrkjQJeBbIAe41s4WSbgRmm9kM4B7gfkmlRC2aiWHdhZIeBhYBVcBVocVChjITwBRJRURdbfOAK0NVJkk6GdgDbKY+uMWm/pqNBxvnnIMYgw2AmT0NPJ2Sdn3S8wrg7Azr3gzc3MIya4DjMpTzrVZX/CPqUhC60Sp8gIBzzoHPIBCLvJwEHfNzvGXjnHOBB5uY+G0GnHOungebmBQV+szPzjlXy4NNTLxl45xz9TzYxMRvM+Ccc/U82MTEb6DmnHP1PNjExFs2zjlXz4NNTGpvoOb3tHHOOQ82sSkuzKPGYIff08Y55zzYxKV7p3wA1pXvaueaOOdc+/NgE5ORfYsAeHvN1mZyOufcvz4PNjEZfkBnOuQmWLCmvL2r4pxz7c6DTUxycxKM7FvEgtUebJxzzoNNjEb3K2bhB+VU1/iINOfcx5sHmxgd1q+YHburWb5he3tXxTnn2pUHmxiN7t8VgPneleac+5jzYBOjob06UZCX8GDjnPvY82ATo9ycBOOG9OCfiz/0mQSccx9rHmxiNn5Ub97fuJN31m5r76o451y78WATs8+NOhAJ/rpwXXtXxTnn2o0Hm5j17NyBowd3569vr23vqjjnXLvxYNMGTj2sN++t387SMh8C7Zz7eIo12EgaL2mxpFJJ16RZ3kHStLB8pqTBScuuDemLJZ3SXJmS7pE0T9J8SdMldQ7p35G0KKT/Q9KgOPc5nVNG9Qbgr297V5pz7uMptmAjKQe4DTgVGAmcJ2lkSrZLgc1mNgz4DXBLWHckMBEYBYwHbpeU00yZV5vZGDMbDawEJoX0t4CSkD4d+HksO9yEvl0LGTOgqwcb59zHVpwtm3FAqZktM7PdwFRgQkqeCcCU8Hw6cJIkhfSpZlZpZsuB0lBexjLNbCtAWL8QsJD+TzPbGbbxOtA/lr1txkLdORQAAByqSURBVKmH9WbBmnJWb97ZfGbnnPsXE2ew6QesSnq9OqSlzWNmVUA50KOJdZssU9JkYB0wArg1TZ0uBZ5JV1lJl0uaLWl2WVlZc/vWauO9K8059zEWZ7BRmrTUXzZmytPa9OiJ2SVAX+Ad4NwGG5K+CpQAv0hXWTO7y8xKzKykV69e6bJ8JIN7dmJknyKemPtB1st2zrl9XZzBZjUwIOl1fyD1TFuXR1IuUAxsamLdZss0s2pgGnBmbZqkk4HrgC+YWeVe79FHNHHcABasKWfeqi3tVQXnnGsXcQabWcBwSUMk5RNd8J+RkmcGcFF4fhbwnEXzuswAJobRakOA4cAbmcpUZBjUXbM5A3g3vD4S+D1RoPkwxv1t1peO7EfH/Bz+9Pr77VkN55xrc7EFm3ANZhLwLFG31sNmtlDSjZK+ELLdA/SQVAp8B7gmrLsQeBhYBPwVuMrMqjOVSdS9NkXSAmAB0Ae4MWzjF0Bn4BFJcyWlBrw206UgjwlH9GPGvA/4cFtFe1XDOefanHyCyMZKSkps9uzZsZS9ZP02zvjflxnYvSMPff1YenTuEMt2nHOurUmaY2Yl6Zb5DAJtbPiBXbj3oqN5f+NOJj34VntXxznn2oQHm3bwyWE9+f74Eby2bCMzl21s7+o451zsPNi0k68cM5CenfP57T+W8OzCdby6dEN7V8k552KT294V+LgqyMvh68cfxH8/8y6vLt1IQvA/E4/kC2P6tnfVnHMu6zzYtKOLPjmYqhpjZN8i7nh+Kd+e+hbryndx2acOIpFI9/tV55zbP/lotDTiHI2Wyc7dVVw9bS7PLlzPYf2K+MwhB3Dppw6iuGNem9bDOef2lo9G2w90zM/lzq+O5WdfPpycRIL//Wcp1zw6v72r5ZxzWeHdaPsQSUwcN5CJ4wZy+/Ol/Pyvi/nDi8uoqjEOPrAznz64F3k5/v3AObf/8WCzj/r68Qfx1Py13Pz0O3Vp/bsVcv+lxzCkZ6d2rJlzzrWef03eR+XlJPjDhSXccf5RzLruZH5/wVh27q5m4l2vUfrhNgAWflDO5h27G637X48t4Jo/z2dHZVWD9B2VVZTv3NMm9XfOuWQebPZhfbsWcurhfejVpQOnjOrNg18/huoa44xbX+GSyW9w2u9e5st3vMqHW+vnWfvn4g95cOZKps5axZduf4V15dEyM+OSybP4zK+e5/2NO/jbwnU8+ubqvarXyo07+fXfFlO+q2WBq6q6hsmvLK8LkrXMjDnvb2Jrxd4FwFv/sYTrn3i7UfqOyipWbNixV2V+HGV7kJCZsT3li87a8l0+23mwecduHpm9iqrqmli38/aacr5x/2zWb63AzCj9cFvW3+vW8G60/ciI3kU89c3j+c9H5vFy6QYuOHYQf35zNef94XWmXv4JunbM46YnFzGkZyeuP30k//HQW1xwz0weueITLFhTzhsrNpGTEGfc+jJbK6pICMYO6sagHi3vllv0wVYuvPcNNmyv5G+L1nPeuIG8vaacwaFrb9WmnXzr5OH0KS6sW+f255fy67+/R35ugus+fygXfXIw68oruObR+Ty/uIzxo3pz5wVjAdhasYd/vvshJx5yAMWFmUfifbBlF797bgl7qo0LPzGIYQd0AWBPdQ0X3DOTt9ds5dF//ySH9Stu9XHeubuK6XNW06NTB04b3acu3cx4ackGVm3eycmHHsiBRQV1y5aVbWf2+5s5e2x/JGFmRBOQN+31ZRtZW76LUw/rQ0FeTovrWFVdQ+5HvH5XWVXNt6fOZcXGnUz7xrEUFdQf7yg4lHPKqANbtB9mxszlm3h49ipeWrKBsm2V/Nshvfj+qSMYfkAXLpk8i6Vl23n0yuM4vH8xNTXWYHj/lp276VKQR06aIf+PvbWau15czi/OGl33fpZtq8QwDuhS0Ch/tpgZP3nyHdZvreDaz4+gV5cO5CUSdfWurjEemPk+nxvZm97FUT3mr97Co2+uocaMrbv20L1TB645dQT5uQm2VewhJyEuvm8W81ZtwQzOOXoAa7bs4sGZ79Ova0e+csxAnpi7hiXrt3P5CQc1eE9SbdheyTcfeosvjOnLxHEDMTMmv7KCR+as5rufPZgfP7mQVZt2sb2yiuEHdOG+V1dw5lH9+emXD6NDbvRZ215Zxa/+tpgB3Toyun8xBXk59OtaSLdO+Vk/nj70OY32GPrcGrXfHLsU5DFz2UYunjyLAd0L6dYxn5nLN3H3hSWcPPJAXl26gYvvnUX/boXk5STYWrGHX50zhm9Pncvpo/vyp5nvc+ZR/fjOZw9hwZotFBfmM6pvUYOTXu1Js7Kqmtv/uZQ7XlhKj075fPOk4dz05CJ27K6ma8c8toTuuZyEOKxvEdO+8QkK8nJ4fdlGzr97Jp8beSAVe6r55+IyHr/qOH72zDvMW1VOyeBuvLRkA3++8pOMHdSNq6fN5bG31lCYl8ORA7sysHtHJhzRjz7FBawtr2DckO7kJMSPnnibB2auJJEQZ43tz/Wnj2TVpp1Mm7WKu19eTpeCXLp1zOfaU0cA0LNLB0b07kKXJv55AV5aUsa3p85lY+ievPlLh/Hp4b14bdlGHnpjJW+tjL6dS3D0oO6ccURfjh3SnfPvnsmH2yo5a2x/KqtqeG3pRm4583BOOvRAamqMB95YSbeOeZx2eJ+6k/fG7ZWc+Mvn2VZRRaf8HLoU5DF2cDd+dfYYCvJy2FNdw+3/XMrQAzrRvWM+j8xZzYbtlazfWsHSsh2cU9Kfn37p8BYFA4Bdu6t5cv4H9OtWiBC3P1/KS0s2kJMQxw3rSd/iAtZvreCHp4/ksj/OZlnZDs4/ZiA3TjisLgj8fdF6Jr+ynBozRvUt5vTRfdhdVcNtzy/lxffK6NIhl88cegC9iwqYOmsV1TXGeeMG8IeXllOYl0PPLvl07pDH9so9PDnpeIo75vHw7FX88PG3GdGniN9NPIKenTtQmJfD9t1V/OHFZdz6XCkJQbeO+Tz49WPpkJvgrDtfo8aMh75+LIf07lK3j3uqa8iRMv5ObfmGHWzaUcmHWyt5cUkZRQV5nHjIARx7UHcAynftoWvH6ET76Jur+c7D80goGrxTXWMMO6AzD1x2DAcWFTB9zmr+85F5jBvcnamXH8tTC9by3Uei/AV5OXTKz2XNll18++ThVFbVcMfzSynIS7C7qoYDiwrIz01w9ckH85+PzKOqxpDg++NH8MtnF1NVY/TsnM+dXx1LyeDujfajfOcezvvD6yxau5W8HHH7+WN5/K01PLVgLZ3yc9ixu5qchPjKuIHcH25pMm5wd95YsYkTD+nFvRcdDcCVD8zh2YXrG5T9ky8exgXHDmrRZypVU0OfPdiksa8Hm1Svlm7gkvtmkZ+b4IenjeScowc0WHbd42+zfMMObpwwigs/Mbhu2Q8ff5ups1aSn5Ngx+5qAIoL8/jUsJ7s3F3Fe+u3Y2bcecFYfv/CMp5asJYzxvTlh6cdygFFBXy4rYLtFVUM6dmJbaHb5PWlG7n8/jkcNbArQ3p25vG5a+jfrZC//MenSEj82y+fx8zYsH03N33xML50ZD9O/OXz9O1ayNeOG8y3ps5l4tEDSCTEu2u3suTD7WyrqO+S+fTBvThl1IH8+C+L+PKR0R3BH3trDUWFeZRti+6Ld05Jf849egAT73qdPdX1n+/chDj4wC7k5yaQoGthHlecMJSXSzfw4MyVjOxbxGtLNzLsgM5cf8ZI7npxGc8vrr9F+KAeHbn80wdRMqg7zy5cx1Pz17J4fdQ12KUgl9NH9+WhN6Lj2a9bIcs37OAzIw5g1+5qXgtz4B01sCv//eXRHNK7C//12AKmzVrFz88czdxVW9hasYcZ8z7g08N78fsLxvLH11bw06ffrdt+1455HNSzE1075lOYn8NT89dyxQlD+f74Q9hdXcO7a7dxeL9iFq3dygMzV1KYl8MRA7ty6mG9+WDLLiY9+BYL1pTXlZefk+AnXxxFZVUN1z+xkA7huOyuqkESpx3ehxnzPmBor06cMaYvKzft5NE31zCoR0d6du7A/NVb6o5v5w65XP3Zg/nKuIEU5kdfVtaVV3DmHa+yZssuxvQv5r8+fyjn3z2TAd07snLTTs4Y3YfC/FweemMlRw7sSun67XWfo/zcBAlBxZ4avnRkP644YSjn3/06m3ZELaCEojyVVTUcOaArHXJzqKoxZi7fSJcOuUz52jh27anmgy27GH9YH95eU85PnlzEzOWb6va/S0EuFXuq2VNtjOjdhd1VNSzbsINTRh3I8AO6MPmV5YzqV8wvzxrDQ7NWkiMx+ZXlHFhcwK3nHcnlf5zDjt1VbNm5hyMHduWtlVsYN7g7d14wlu6hZfDtqW8xY94H1Fh0a/jiwjxOPKQXkrjiT3OAKAj89MuHccWf3qT0w+3061rIL84azXWPv82GbZU8dPmxdS26HZVVvPBeGT95chEbtlfyq3OO4JZn3mXNll3k5yT41snDueATg7jlmXcZ3b+Yc0oG8OO/LKJjfg7fO+UQ7n/9fa5/YiHf/ezBbNheyZTX3ucHpx3KKaN6s2zDDir2VHNo7yIG9ujYklNPIx5sWml/CzYAKzbsoHNBLj3T3LJgd1UNs1Zs4hMH9WjwjW/15p18/rcvMW5IDy47fgjlu/bw5Py1zF+9hU75uRzUqxNvrdzC+q0VVNUY1546gm+cMLTZuvzxtRXc9+oKVm/axZlj+/H98SPqvi0+MnsV35s+n9H9i3ns348jJyEef2sN33l4LjUGA7oX8verT6hrXVXsqeaZt9dSsaeGHZVV3PLXd9lTbYzsU8TdF5Wwo7KK0259mZJB3TinZADdOuVz3NAe5OYkWL+1gk07dmMG67dWMGvFJhat3UqNRS22xeu28WEIUMcP78mKjTsY0buIX58zhi4FeVTsqeaxt9aQI3Fw7y6M6V/cqBUx5/3NTJ+zirPG9mfsoO784531DO3Vmd7FBfz2H0t4av5ayrZVct1ph5Kfm+Bnz7zLtoo9jO7flbdWbubCTwzmhi+Mqitv6hsruebRBYzqW8Sysh0cN6wHlxw3hA3bKzllVO+642JmXPf42zw4cyXnlPRn8bptzFtdzpCenVi1aScdchMYsHN3NQV5CSr21NApP4dfnD2GgrwE1TXwiaE96Nwht6578NA+RazfWsH3ps/nwk8M4rxxA3lq/lrueKGUt9dspWN+DmeP7c+1nz+UgrwcNm6v5PVlm+iYn8Ph/YvTfvZKP9zODx5fwLWnHsqYAV0p21ZJ9075/M//vcetz5UCcOWJQ/nuZw9mbXkFTy1YC0TXNSr2VHPW2AEc3j860a7fWsGUV1fw0pIN3PTFwygqzOOGGQvZvHM3lXtqqKqp4ciB3XjhvTJ2VFaxM3yB+uIRffm/dz6kY34OX/vUEEb2KaJTh1zG9C+msqqGpxes5b5XV9AxP4fR/bsybdYqdu2ppmRQN35z7hH07VrfJTxrxSa+NnlWXVB84LJj+P2Ly3h5SRlXnDCUb508vK6LqnY/TvvdS4zqV8wd5x9V1/VZU2N8+Y5XMTPuv+wYigryeHfdVq59dAE/OG0kYwd1Y82WXZx9x6vs2F3N/0w8gmcWrOXPb66hOvwU4pYzR3PkwG68vaacR2av4tJPHdRskDAzrvhTfWvm4k8O5kdnjGxx67g5HmxaaX8MNnsrte881apNO/nafbM4bljPVn8o0123qKkx7n1lOScdemCDIdxrtuzi8bfWcPzwnozu3zVjmcs37KB8154GJ/7KquoG/+AttaOyivteXcHgHp0aXJvJtuoaq+uG2ri9klv++i4rN+1kaK/OfP/UEY365f++aD3feXgu1TXG379zAv2STnbJamqMnz+7mDtfWErnDrl8/fiDeHFJGYN6dOT600dSVJDHC++V8fcQAD838kAGdG/9N1YzY9eeagrzcrJ2UtpdVcNNTy3i+OG9+OzIA7NSZq1lZdv53vT5fHJoD7ZVRO/xQb068cBlxzS4lpjJzt1V1FjUWktn4/ZK7nxhKWbwg9NHsmt3NWXbKjOe6CurqsnPSTQ6dpVV1Q2uAaWzcuNOLr7vDZaV7SAhuODYQZw44gCOG9qT/Ny9u2a3ecdufvuPJZwxpg9jBzXuovsoPNi00scp2LRESy92u+xZV17Btoo9DD+wS7N5X16ygQHdC1s10OPjwsx4pXQjo/oWxXLRuy1s2RkFh/GjenPMQT3auzpN8mDTSh5snHOu9XxuNOecc+3Kg41zzrnYebBxzjkXu1iDjaTxkhZLKpV0TZrlHSRNC8tnShqctOzakL5Y0inNlSnpHknzJM2XNF1S55D+aUlvSqqSdFac++uccy692IKNpBzgNuBUYCRwnqSRKdkuBTab2TDgN8AtYd2RwERgFDAeuF1STjNlXm1mY8xsNLASmBTSVwIXAw/GsqPOOeeaFWfLZhxQambLzGw3MBWYkJJnAjAlPJ8OnKRojO0EYKqZVZrZcqA0lJexTDPbChDWLwQspK8ws/lAvLPeOeecyyjOYNMPWJX0enVIS5vHzKqAcqBHE+s2WaakycA6YARwa2sqK+lySbMlzS4rK2t+Beeccy0WZ7BJ9yvA1B/1ZMrT2vToidklQF/gHeDcllWzbt27zKzEzEp69erVmlWdc841I85bDKwGBiS97g98kCHPakm5QDGwqZl1myzTzKolTQO+B0zem4rPmTNng6T392ZdoCewYS/Xjdu+WjevV+t4vVpvX63bv1q9Mk4XHWewmQUMlzQEWEN0wf8rKXlmABcBrwFnAc+ZmUmaATwo6ddELZXhwBtELZtGZYbrNEPNrDQ8PwN4l71kZnvdtJE0O9MvaNvbvlo3r1freL1ab1+t28epXrEFGzOrkjQJeBbIAe41s4WSbgRmm9kM4B7gfkmlRC2aiWHdhZIeBhYBVcBVZlYNkKHMBDBFUhFRQJoHXBnyHw08BnQDzpD0YzOrn2bXOedc7GK9U6eZPQ08nZJ2fdLzCuDsDOveDNzcwjJrgOMylDOLqLvNOedcO/EZBLLvrvauQBP21bp5vVrH69V6+2rdPjb18lmfnXPOxc5bNs4552LnwcY551zsPNhkUXMTj7ZhPQZI+qekdyQtlPStkH6DpDWS5obH59uhbiskLQjbnx3Sukv6u6Ql4W+3Nq7TIUnHZK6krZK+3V7HS9K9kj6U9HZSWtpjpMjvwmduvqSj2rhev5D0btj2Y5K6hvTBknYlHbs727heGd87ZZjktw3rNi2pXiskzQ3pbXLMmjg/xPsZMzN/ZOFBNBR7KXAQkE80/HpkO9WlD3BUeN4FeI9o4tIbgP9s5+O0AuiZkvZz4Jrw/BrglnZ+H9cR/TitXY4X8GngKODt5o4R8HngGaIh/8cCM9u4Xp8DcsPzW5LqNTg5Xzscr7TvXfg/mAd0AIaE/9mctqxbyvJfAde35TFr4vwQ62fMWzbZ05KJR9uEma01szfD821E0/ekzku3L0mekHUK8MV2rMtJwFIz29sZJD4yM3uR6HdnyTIdownAHy3yOtBVUp+2qpeZ/c2ieQ0BXqcdfmaQ4XhlkmmS3zavW/gB+jnAQ3FtP0OdMp0fYv2MebDJnpZMPNrmFN0j6EhgZkiaFJrC97Z1d1VgwN8kzZF0eUg70MzWQvSPABzQDvWqNZGG//ztfbxqZTpG+9Ln7mtE34BrDZH0lqQXJB3fDvVJ997tS8freGC9mS1JSmvTY5Zyfoj1M+bBJntaMvFom1J0A7k/A9+26BYMdwBDgSOAtURN+LZ2nJkdRXRPoqskfbod6pCWpHzgC8AjIWlfOF7N2Sc+d5KuI5rt44GQtBYYaGZHAt8hmn6qqA2rlOm92yeOV3AeDb/YtOkxS3N+yJg1TVqrj5kHm+xpycSjbUZSHtEH6QEzexTAzNabWbVFMy78gRi7DzIxsw/C3w+JphEaB6yvbZaHvx+2db2CU4E3zWx9qGO7H68kmY5Ru3/uJF0EnA6cb6GTP3RTbQzP5xBdGzm4rerUxHvX7scLQNHEw18GptWmteUxS3d+IObPmAeb7KmbeDR8Q55INNFomwt9wfcA75jZr5PSk/tZvwS8nbpuzPXqJKlL7XOii8tvUz8hK+HvE21ZryQNvmm29/FKkekYzQAuDCOGjgXKa7tC2oKk8cD3gS+Y2c6k9F6K7qyLpIOIJtNd1ob1yvTezQAmKrol/RDqJ/ltaycD75rZ6tqEtjpmmc4PxP0Zi3vkw8fpQTRq4z2ibyTXtWM9PkXUzJ0PzA2PzwP3AwtC+gygTxvX6yCikUDzgIW1x4johnn/AJaEv93b4Zh1BDYCxUlp7XK8iALeWmAP0bfKSzMdI6IujtvCZ24BUNLG9Sol6s+v/ZzdGfKeGd7jecCbwBltXK+M7x1wXThei4FT2/q9DOn3AVek5G2TY9bE+SHWz5hPV+Occy523o3mnHMudh5snHPOxc6DjXPOudh5sHHOORc7DzbOOedi58HGuTYg6URJT36E9b8o6frmc+5V2TdLWiVpe0p6hzBDcamkmWFqk9pljWZOlpQv6cXwg0XnGvBg49z+4f8Bt3/UQmp/NJjiL6SfHeFSYLOZDQN+QzSrM5JGEv1oeRQwHrhdUo5FE9D+Azj3o9bT/evxYONcIOmrkt4I9xL5fdKvubdL+pWkNyX9Q1KvkH6EpNdVfy+X2vt/DJP0f5LmhXWGhk10ljRd0f1fHgi/5EbSzyQtCuX8Mk29DgYqzWxDeH2fpDslvSTpPUmnh/QcRfeXmRXK+kZIP1HR/UseJPpRXgNm9rql/0V48izA04GTQp2bmjn5ceD8Vh569zHgwcY5QNKhRN/IjzOzI4Bq6k+anYjmTDsKeAH4UUj/I/B9MxtNdBKvTX8AuM3MxgCfJPoFOUSz636b6N4hBwHHSepONJ3KqFDOTWmqdxzRL8qTDQZOAE4D7pRUQNQSKTezo4Gjga+HKVkgCgbXmdnIVhyWutl+LbqNQDnRr8ybmgX47bBt5xrwvlXnIicBY4FZocFRSP1EhDXUT5j4J+BRScVAVzN7IaRPAR4Jc7/1M7PHAMysAiCU+YaFubAU3Z1xMNE9YCqAuyU9BaS7rtMHKEtJe9iiSSaXSFoGjCCaa260pLNCnmKi+bV2h20vb+UxyTTbb8ZZgM2sWtJuSV0suleKc4AHG+dqCZhiZte2IG9TczylOxHXqkx6Xk10h8sqSeOIgt1EYBLwmZT1dhEFjqbqUBsE/sPMnm1QIelEYEcT9cqkdrbf1eGifzHRjcCamwW4A1EAda6Od6M5F/kHcJakA6DufuyDwrIEUNta+ArwspmVA5tVf4OrC4AXLLovyGpJXwzldJDUMdNGFd1TpNjMnibqYjsiTbZ3gGEpaWdLSoTrQQcRTSr5LHClounjkXRwmF17byXPAnwW8JxFkylmnDlZUg+gzMz2fITtun9B3rJxDjCzRZJ+QHQX0QTRLL1XAe8TtQpGSZpDdN2idrTVRUTXSzoSTQV/SUi/APi9pBtDOWc3sekuwBPhmouAq9PkeRH4lSRZ/cy5i4muHx1INHtwhaS7ibrm3gwX8stowS22Jf2cKIh2lLQauNvMbiCahv5+SaVELZqJ4VgtlPQwsIjohmlXmVl1KO7fgKeb26b7+PFZn51rhqTtZta5nevwW+AvZvZ/ku4DnjSz6e1Zp3QkPQpca2aL27subt/i3WjO7R9+SnTPnX2WopsGPu6BxqXjLRvnnHOx85aNc8652Hmwcc45FzsPNs4552LnwcY551zsPNg455yL3f8HNZOH6gl2Dk4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6781820570077499\n"
     ]
    }
   ],
   "source": [
    "layers_dims = [datax_train.shape[0],14,8,4,1]\n",
    "parameters = model(datax_train, datay_train, layers_dims, optimizer = \"adam\", learning_rate = 0.0007, mini_batch_size = 2048, beta = betar, beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8, num_epochs = 20000)\n",
    "predictions = predict(datax_train, datay_train, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6163482618227373"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.f1_score(datay_train[0],predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('/Users/emiliano/Downloads/nlp-getting-started/test.csv')\n",
    "test = test.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nkey1,Nkey2,Nkey3 = test.keyword.apply(txt.automated_readability_index),test.keyword.apply(txt.coleman_liau_index),test.keyword.apply(txt.linsear_write_formula)\n",
    "Nkey1,Nkey2,Nkey3 = Nkey1 + abs(Nkey1.min()), Nkey2 + abs(Nkey2.min()), Nkey3 + abs(Nkey3.min())\n",
    "Nloc1,Nloc2,Nloc3 = test.location.apply(txt.automated_readability_index),test.location.apply(txt.coleman_liau_index),test.location.apply(txt.linsear_write_formula)\n",
    "Nloc1,Nloc2,Nloc3 = Nloc1 + abs(Nloc1.min()), Nloc2 + abs(Nloc2.min()), Nloc3 + abs(Nloc3.min())\n",
    "Ntxt1,Ntxt2,Ntxt3 = test.text.apply(txt.automated_readability_index),test.text.apply(txt.coleman_liau_index),test.text.apply(txt.linsear_write_formula)\n",
    "Ntxt1,Ntxt2,Ntxt3 = Ntxt1 + abs(Ntxt1.min()), Ntxt2 + abs(Ntxt2.min()), Ntxt3 + abs(Ntxt3.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>Nkey1</th>\n",
       "      <th>Nkey2</th>\n",
       "      <th>Nkey3</th>\n",
       "      <th>Nloc1</th>\n",
       "      <th>Nloc2</th>\n",
       "      <th>Nloc3</th>\n",
       "      <th>Ntxt1</th>\n",
       "      <th>Ntxt2</th>\n",
       "      <th>Ntxt3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.3</td>\n",
       "      <td>23.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.8</td>\n",
       "      <td>23.59</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.3</td>\n",
       "      <td>23.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.9</td>\n",
       "      <td>31.52</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.3</td>\n",
       "      <td>23.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.9</td>\n",
       "      <td>22.33</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.3</td>\n",
       "      <td>23.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.6</td>\n",
       "      <td>42.51</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.3</td>\n",
       "      <td>23.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.4</td>\n",
       "      <td>24.31</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   0                                  Just happened a terrible car crash   \n",
       "1   2                   Heard about #earthquake is different cities, s...   \n",
       "2   3                   there is a forest fire at spot pond, geese are...   \n",
       "3   9                            Apocalypse lighting. #Spokane #wildfires   \n",
       "4  11                       Typhoon Soudelor kills 28 in China and Taiwan   \n",
       "\n",
       "   Nkey1  Nkey2  Nkey3  Nloc1  Nloc2  Nloc3  Ntxt1  Ntxt2  Ntxt3  \n",
       "0    2.2    6.4    0.0   14.3   23.8    0.0   11.8  23.59    3.5  \n",
       "1    2.2    6.4    0.0   14.3   23.8    0.0   19.9  31.52    6.0  \n",
       "2    2.2    6.4    0.0   14.3   23.8    0.0   14.9  22.33    9.0  \n",
       "3    2.2    6.4    0.0   14.3   23.8    0.0   31.6  42.51    2.5  \n",
       "4    2.2    6.4    0.0   14.3   23.8    0.0   12.4  24.31    3.5  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Nkey1'],test['Nkey2'],test['Nkey3']=Nkey1,Nkey2,Nkey3\n",
    "test['Nloc1'],test['Nloc2'],test['Nloc3']=Nloc1,Nloc2,Nloc3\n",
    "test['Ntxt1'],test['Ntxt2'],test['Ntxt3']=Ntxt1,Ntxt2,Ntxt3\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>Nkey1</th>\n",
       "      <th>Nkey2</th>\n",
       "      <th>Nkey3</th>\n",
       "      <th>Nloc1</th>\n",
       "      <th>Nloc2</th>\n",
       "      <th>Nloc3</th>\n",
       "      <th>Ntxt1</th>\n",
       "      <th>Ntxt2</th>\n",
       "      <th>Ntxt3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>0.027431</td>\n",
       "      <td>0.068958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.09316</td>\n",
       "      <td>0.170965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.160763</td>\n",
       "      <td>0.327457</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>0.027431</td>\n",
       "      <td>0.068958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.09316</td>\n",
       "      <td>0.170965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.271117</td>\n",
       "      <td>0.437535</td>\n",
       "      <td>0.342857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>0.027431</td>\n",
       "      <td>0.068958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.09316</td>\n",
       "      <td>0.170965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.202997</td>\n",
       "      <td>0.309967</td>\n",
       "      <td>0.514286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>0.027431</td>\n",
       "      <td>0.068958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.09316</td>\n",
       "      <td>0.170965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.430518</td>\n",
       "      <td>0.590089</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>0.027431</td>\n",
       "      <td>0.068958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.09316</td>\n",
       "      <td>0.170965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.168937</td>\n",
       "      <td>0.337451</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   0                                  Just happened a terrible car crash   \n",
       "1   2                   Heard about #earthquake is different cities, s...   \n",
       "2   3                   there is a forest fire at spot pond, geese are...   \n",
       "3   9                            Apocalypse lighting. #Spokane #wildfires   \n",
       "4  11                       Typhoon Soudelor kills 28 in China and Taiwan   \n",
       "\n",
       "      Nkey1     Nkey2  Nkey3    Nloc1     Nloc2  Nloc3     Ntxt1     Ntxt2  \\\n",
       "0  0.027431  0.068958    0.0  0.09316  0.170965    0.0  0.160763  0.327457   \n",
       "1  0.027431  0.068958    0.0  0.09316  0.170965    0.0  0.271117  0.437535   \n",
       "2  0.027431  0.068958    0.0  0.09316  0.170965    0.0  0.202997  0.309967   \n",
       "3  0.027431  0.068958    0.0  0.09316  0.170965    0.0  0.430518  0.590089   \n",
       "4  0.027431  0.068958    0.0  0.09316  0.170965    0.0  0.168937  0.337451   \n",
       "\n",
       "      Ntxt3  \n",
       "0  0.200000  \n",
       "1  0.342857  \n",
       "2  0.514286  \n",
       "3  0.142857  \n",
       "4  0.200000  "
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Ntxt1'] = test['Ntxt1'].apply(lambda x: normalize(x,test['Ntxt1'].max()))\n",
    "test['Ntxt2'] = test['Ntxt2'].apply(lambda x: normalize(x,test['Ntxt2'].max()))\n",
    "test['Ntxt3'] = test['Ntxt3'].apply(lambda x: normalize(x,test['Ntxt3'].max()))\n",
    "test['Nkey1'] = test['Nkey1'].apply(lambda x: normalize(x,test['Nkey1'].max()))\n",
    "test['Nkey2'] = test['Nkey2'].apply(lambda x: normalize(x,test['Nkey2'].max()))\n",
    "test['Nkey3'] = test['Nkey3'].apply(lambda x: normalize(x,test['Nkey3'].max()))\n",
    "test['Nloc1'] = test['Nloc1'].apply(lambda x: normalize(x,test['Nloc1'].max()))\n",
    "test['Nloc2'] = test['Nloc2'].apply(lambda x: normalize(x,test['Nloc2'].max()))\n",
    "test['Nloc3'] = test['Nloc3'].apply(lambda x: normalize(x,test['Nloc3'].max()))\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 3263)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = ['Nkey1','Nkey2','Nkey3', 'Nloc1','Nloc2','Nloc3','Ntxt1','Ntxt2','Ntxt3']\n",
    "datax_test = test.loc[:, feature_cols].values.T\n",
    "datax_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 1, 1, 1]])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(datax_test,datay_train,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
